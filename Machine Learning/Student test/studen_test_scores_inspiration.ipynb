{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:35.653285Z",
     "start_time": "2026-01-22T08:41:35.253422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "#import winsound\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, log_loss, brier_score_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier"
   ],
   "id": "e3d6386500f388f9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:36.278532Z",
     "start_time": "2026-01-22T08:41:35.657919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "# df_original = pd.read_csv(\"diabetes dataset.csv\")\n",
    "\n",
    "\n",
    "MODEL = \"lgbm\"\n",
    "#MODEL = \"xgb\"\n",
    "sound = False                            # beep after each validation, beep extra after all validations\n",
    "include_original = False                 # use the original database as additional training data?\n",
    "validate_models = False                  # compare a lot of models with different model parameters?\n",
    "submit_prediction = not validate_models # create a submission?\n",
    "verbose = False                         # print a lot of variables for debugging purposes?"
   ],
   "id": "d111bda801c22450",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:36.340378Z",
     "start_time": "2026-01-22T08:41:36.320384Z"
    }
   },
   "cell_type": "code",
   "source": "# df_original",
   "id": "a5d73fa2ffa7f828",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:36.415601Z",
     "start_time": "2026-01-22T08:41:36.386819Z"
    }
   },
   "cell_type": "code",
   "source": "df_train",
   "id": "16d2984bde325654",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            id  age  gender   course  study_hours  class_attendance  \\\n",
       "0            0   21  female     b.sc         7.91              98.8   \n",
       "1            1   18   other  diploma         4.95              94.8   \n",
       "2            2   20  female     b.sc         4.68              92.6   \n",
       "3            3   19    male     b.sc         2.00              49.5   \n",
       "4            4   23    male      bca         7.65              86.9   \n",
       "...        ...  ...     ...      ...          ...               ...   \n",
       "629995  629995   18  female   b.tech         4.86              70.7   \n",
       "629996  629996   21  female       ba         7.08              54.4   \n",
       "629997  629997   24    male      bca         0.64              44.2   \n",
       "629998  629998   20    male    b.com         1.54              75.1   \n",
       "629999  629999   18   other   b.tech         3.94              75.3   \n",
       "\n",
       "       internet_access  sleep_hours sleep_quality   study_method  \\\n",
       "0                   no          4.9       average  online videos   \n",
       "1                  yes          4.7          poor     self-study   \n",
       "2                  yes          5.8          poor       coaching   \n",
       "3                  yes          8.3       average    group study   \n",
       "4                  yes          9.6          good     self-study   \n",
       "...                ...          ...           ...            ...   \n",
       "629995             yes          4.1          good          mixed   \n",
       "629996             yes          4.5       average          mixed   \n",
       "629997             yes          4.3          poor  online videos   \n",
       "629998             yes          8.2       average    group study   \n",
       "629999             yes          5.8          poor  online videos   \n",
       "\n",
       "       facility_rating exam_difficulty  exam_score  \n",
       "0                  low            easy      78.300  \n",
       "1               medium        moderate      46.700  \n",
       "2                 high        moderate      99.000  \n",
       "3                 high        moderate      63.900  \n",
       "4                 high            easy     100.000  \n",
       "...                ...             ...         ...  \n",
       "629995            high        moderate      69.500  \n",
       "629996             low        moderate      78.900  \n",
       "629997             low        moderate      19.599  \n",
       "629998            high        moderate      59.100  \n",
       "629999             low            easy      37.200  \n",
       "\n",
       "[630000 rows x 13 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>course</th>\n",
       "      <th>study_hours</th>\n",
       "      <th>class_attendance</th>\n",
       "      <th>internet_access</th>\n",
       "      <th>sleep_hours</th>\n",
       "      <th>sleep_quality</th>\n",
       "      <th>study_method</th>\n",
       "      <th>facility_rating</th>\n",
       "      <th>exam_difficulty</th>\n",
       "      <th>exam_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>b.sc</td>\n",
       "      <td>7.91</td>\n",
       "      <td>98.8</td>\n",
       "      <td>no</td>\n",
       "      <td>4.9</td>\n",
       "      <td>average</td>\n",
       "      <td>online videos</td>\n",
       "      <td>low</td>\n",
       "      <td>easy</td>\n",
       "      <td>78.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>other</td>\n",
       "      <td>diploma</td>\n",
       "      <td>4.95</td>\n",
       "      <td>94.8</td>\n",
       "      <td>yes</td>\n",
       "      <td>4.7</td>\n",
       "      <td>poor</td>\n",
       "      <td>self-study</td>\n",
       "      <td>medium</td>\n",
       "      <td>moderate</td>\n",
       "      <td>46.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>female</td>\n",
       "      <td>b.sc</td>\n",
       "      <td>4.68</td>\n",
       "      <td>92.6</td>\n",
       "      <td>yes</td>\n",
       "      <td>5.8</td>\n",
       "      <td>poor</td>\n",
       "      <td>coaching</td>\n",
       "      <td>high</td>\n",
       "      <td>moderate</td>\n",
       "      <td>99.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>b.sc</td>\n",
       "      <td>2.00</td>\n",
       "      <td>49.5</td>\n",
       "      <td>yes</td>\n",
       "      <td>8.3</td>\n",
       "      <td>average</td>\n",
       "      <td>group study</td>\n",
       "      <td>high</td>\n",
       "      <td>moderate</td>\n",
       "      <td>63.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>male</td>\n",
       "      <td>bca</td>\n",
       "      <td>7.65</td>\n",
       "      <td>86.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>9.6</td>\n",
       "      <td>good</td>\n",
       "      <td>self-study</td>\n",
       "      <td>high</td>\n",
       "      <td>easy</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629995</th>\n",
       "      <td>629995</td>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>b.tech</td>\n",
       "      <td>4.86</td>\n",
       "      <td>70.7</td>\n",
       "      <td>yes</td>\n",
       "      <td>4.1</td>\n",
       "      <td>good</td>\n",
       "      <td>mixed</td>\n",
       "      <td>high</td>\n",
       "      <td>moderate</td>\n",
       "      <td>69.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629996</th>\n",
       "      <td>629996</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>ba</td>\n",
       "      <td>7.08</td>\n",
       "      <td>54.4</td>\n",
       "      <td>yes</td>\n",
       "      <td>4.5</td>\n",
       "      <td>average</td>\n",
       "      <td>mixed</td>\n",
       "      <td>low</td>\n",
       "      <td>moderate</td>\n",
       "      <td>78.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629997</th>\n",
       "      <td>629997</td>\n",
       "      <td>24</td>\n",
       "      <td>male</td>\n",
       "      <td>bca</td>\n",
       "      <td>0.64</td>\n",
       "      <td>44.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>4.3</td>\n",
       "      <td>poor</td>\n",
       "      <td>online videos</td>\n",
       "      <td>low</td>\n",
       "      <td>moderate</td>\n",
       "      <td>19.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629998</th>\n",
       "      <td>629998</td>\n",
       "      <td>20</td>\n",
       "      <td>male</td>\n",
       "      <td>b.com</td>\n",
       "      <td>1.54</td>\n",
       "      <td>75.1</td>\n",
       "      <td>yes</td>\n",
       "      <td>8.2</td>\n",
       "      <td>average</td>\n",
       "      <td>group study</td>\n",
       "      <td>high</td>\n",
       "      <td>moderate</td>\n",
       "      <td>59.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629999</th>\n",
       "      <td>629999</td>\n",
       "      <td>18</td>\n",
       "      <td>other</td>\n",
       "      <td>b.tech</td>\n",
       "      <td>3.94</td>\n",
       "      <td>75.3</td>\n",
       "      <td>yes</td>\n",
       "      <td>5.8</td>\n",
       "      <td>poor</td>\n",
       "      <td>online videos</td>\n",
       "      <td>low</td>\n",
       "      <td>easy</td>\n",
       "      <td>37.200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630000 rows × 13 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:36.705149Z",
     "start_time": "2026-01-22T08:41:36.695576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_test\n",
    "# df_train['id'].dtype"
   ],
   "id": "753e9f46279a0b51",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            id  age  gender   course  study_hours  class_attendance  \\\n",
       "0       630000   24   other       ba         6.85              65.2   \n",
       "1       630001   18    male  diploma         6.61              45.0   \n",
       "2       630002   24  female   b.tech         6.60              98.5   \n",
       "3       630003   24    male  diploma         3.03              66.3   \n",
       "4       630004   20  female   b.tech         2.03              42.4   \n",
       "...        ...  ...     ...      ...          ...               ...   \n",
       "269995  899995   21   other    b.com         2.55              82.3   \n",
       "269996  899996   17  female    b.com         0.49              46.4   \n",
       "269997  899997   22    male      bba         6.62              74.7   \n",
       "269998  899998   22   other       ba         4.08              51.8   \n",
       "269999  899999   20  female    b.com         5.86              59.7   \n",
       "\n",
       "       internet_access  sleep_hours sleep_quality   study_method  \\\n",
       "0                  yes          5.2          poor    group study   \n",
       "1                   no          9.3          poor       coaching   \n",
       "2                  yes          6.2          good    group study   \n",
       "3                  yes          5.7       average          mixed   \n",
       "4                  yes          9.2       average       coaching   \n",
       "...                ...          ...           ...            ...   \n",
       "269995             yes          8.4       average          mixed   \n",
       "269996             yes          8.8          good          mixed   \n",
       "269997             yes          5.5          good       coaching   \n",
       "269998             yes          8.7          poor  online videos   \n",
       "269999             yes          8.9          poor          mixed   \n",
       "\n",
       "       facility_rating exam_difficulty  \n",
       "0                 high            easy  \n",
       "1                  low            easy  \n",
       "2               medium        moderate  \n",
       "3               medium        moderate  \n",
       "4                  low        moderate  \n",
       "...                ...             ...  \n",
       "269995          medium            hard  \n",
       "269996             low            easy  \n",
       "269997            high            easy  \n",
       "269998            high        moderate  \n",
       "269999          medium        moderate  \n",
       "\n",
       "[270000 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>course</th>\n",
       "      <th>study_hours</th>\n",
       "      <th>class_attendance</th>\n",
       "      <th>internet_access</th>\n",
       "      <th>sleep_hours</th>\n",
       "      <th>sleep_quality</th>\n",
       "      <th>study_method</th>\n",
       "      <th>facility_rating</th>\n",
       "      <th>exam_difficulty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>630000</td>\n",
       "      <td>24</td>\n",
       "      <td>other</td>\n",
       "      <td>ba</td>\n",
       "      <td>6.85</td>\n",
       "      <td>65.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>5.2</td>\n",
       "      <td>poor</td>\n",
       "      <td>group study</td>\n",
       "      <td>high</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>630001</td>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>diploma</td>\n",
       "      <td>6.61</td>\n",
       "      <td>45.0</td>\n",
       "      <td>no</td>\n",
       "      <td>9.3</td>\n",
       "      <td>poor</td>\n",
       "      <td>coaching</td>\n",
       "      <td>low</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>630002</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "      <td>b.tech</td>\n",
       "      <td>6.60</td>\n",
       "      <td>98.5</td>\n",
       "      <td>yes</td>\n",
       "      <td>6.2</td>\n",
       "      <td>good</td>\n",
       "      <td>group study</td>\n",
       "      <td>medium</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>630003</td>\n",
       "      <td>24</td>\n",
       "      <td>male</td>\n",
       "      <td>diploma</td>\n",
       "      <td>3.03</td>\n",
       "      <td>66.3</td>\n",
       "      <td>yes</td>\n",
       "      <td>5.7</td>\n",
       "      <td>average</td>\n",
       "      <td>mixed</td>\n",
       "      <td>medium</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>630004</td>\n",
       "      <td>20</td>\n",
       "      <td>female</td>\n",
       "      <td>b.tech</td>\n",
       "      <td>2.03</td>\n",
       "      <td>42.4</td>\n",
       "      <td>yes</td>\n",
       "      <td>9.2</td>\n",
       "      <td>average</td>\n",
       "      <td>coaching</td>\n",
       "      <td>low</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269995</th>\n",
       "      <td>899995</td>\n",
       "      <td>21</td>\n",
       "      <td>other</td>\n",
       "      <td>b.com</td>\n",
       "      <td>2.55</td>\n",
       "      <td>82.3</td>\n",
       "      <td>yes</td>\n",
       "      <td>8.4</td>\n",
       "      <td>average</td>\n",
       "      <td>mixed</td>\n",
       "      <td>medium</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269996</th>\n",
       "      <td>899996</td>\n",
       "      <td>17</td>\n",
       "      <td>female</td>\n",
       "      <td>b.com</td>\n",
       "      <td>0.49</td>\n",
       "      <td>46.4</td>\n",
       "      <td>yes</td>\n",
       "      <td>8.8</td>\n",
       "      <td>good</td>\n",
       "      <td>mixed</td>\n",
       "      <td>low</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269997</th>\n",
       "      <td>899997</td>\n",
       "      <td>22</td>\n",
       "      <td>male</td>\n",
       "      <td>bba</td>\n",
       "      <td>6.62</td>\n",
       "      <td>74.7</td>\n",
       "      <td>yes</td>\n",
       "      <td>5.5</td>\n",
       "      <td>good</td>\n",
       "      <td>coaching</td>\n",
       "      <td>high</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269998</th>\n",
       "      <td>899998</td>\n",
       "      <td>22</td>\n",
       "      <td>other</td>\n",
       "      <td>ba</td>\n",
       "      <td>4.08</td>\n",
       "      <td>51.8</td>\n",
       "      <td>yes</td>\n",
       "      <td>8.7</td>\n",
       "      <td>poor</td>\n",
       "      <td>online videos</td>\n",
       "      <td>high</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269999</th>\n",
       "      <td>899999</td>\n",
       "      <td>20</td>\n",
       "      <td>female</td>\n",
       "      <td>b.com</td>\n",
       "      <td>5.86</td>\n",
       "      <td>59.7</td>\n",
       "      <td>yes</td>\n",
       "      <td>8.9</td>\n",
       "      <td>poor</td>\n",
       "      <td>mixed</td>\n",
       "      <td>medium</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270000 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:36.806295Z",
     "start_time": "2026-01-22T08:41:36.803355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "def suppress_python_output():\n",
    "    \"\"\"\n",
    "    Redirect Python-level stdout/stderr to os.devnull.\n",
    "    Idempotent: repeated calls do nothing.\n",
    "    \"\"\"\n",
    "    if getattr(suppress_python_output, \"_active\", False):\n",
    "        return\n",
    "    suppress_python_output._old_stdout = sys.stdout\n",
    "    suppress_python_output._old_stderr = sys.stderr\n",
    "    suppress_python_output._devnull = open(os.devnull, \"w\")\n",
    "    sys.stdout = suppress_python_output._devnull\n",
    "    sys.stderr = suppress_python_output._devnull\n",
    "    suppress_python_output._active = True\n",
    "\n",
    "\n",
    "def restore_python_output():\n",
    "    \"\"\"\n",
    "    Restore Python-level stdout/stderr previously redirected by suppress_python_output.\n",
    "    Safe to call even if not active.\n",
    "    \"\"\"\n",
    "    if not getattr(suppress_python_output, \"_active\", False):\n",
    "        return\n",
    "    try:\n",
    "        sys.stdout.flush()\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        sys.stderr.flush()\n",
    "    except Exception:\n",
    "        pass\n",
    "    # close devnull and restore originals\n",
    "    try:\n",
    "        suppress_python_output._devnull.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "    sys.stdout = suppress_python_output._old_stdout\n",
    "    sys.stderr = suppress_python_output._old_stderr\n",
    "    suppress_python_output._active = False"
   ],
   "id": "2da769cddff60e9",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:36.873966Z",
     "start_time": "2026-01-22T08:41:36.867029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# concat df_train and df_original to df_train\n",
    "# ignore columns that exist in df_original only\n",
    "# fill the id column for rows from df_original with values from -100000 to -1\n",
    "originals = 1\n",
    "for _ in range(originals):\n",
    "    if include_original:\n",
    "        df_orig_aligned = df_original.reindex(columns=df_train.columns)  # drop columns that exist only in df_original\n",
    "        start = -len(df_original)\n",
    "        ids = np.arange(start, 0)\n",
    "        try:  # try to cast ids to the same dtype as df_train['id'], fallback to object\n",
    "            ids = ids.astype(df_train['id'].dtype)\n",
    "        except Exception:\n",
    "            ids = ids.astype(object)\n",
    "\n",
    "        df_orig_aligned.loc[:, 'id'] = ids\n",
    "        df_train = pd.concat([df_train, df_orig_aligned], ignore_index=True, sort=False)  # concat keeping df_train's column set\n",
    "df_train"
   ],
   "id": "2d51aa9a34dd5087",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            id  age  gender   course  study_hours  class_attendance  \\\n",
       "0            0   21  female     b.sc         7.91              98.8   \n",
       "1            1   18   other  diploma         4.95              94.8   \n",
       "2            2   20  female     b.sc         4.68              92.6   \n",
       "3            3   19    male     b.sc         2.00              49.5   \n",
       "4            4   23    male      bca         7.65              86.9   \n",
       "...        ...  ...     ...      ...          ...               ...   \n",
       "629995  629995   18  female   b.tech         4.86              70.7   \n",
       "629996  629996   21  female       ba         7.08              54.4   \n",
       "629997  629997   24    male      bca         0.64              44.2   \n",
       "629998  629998   20    male    b.com         1.54              75.1   \n",
       "629999  629999   18   other   b.tech         3.94              75.3   \n",
       "\n",
       "       internet_access  sleep_hours sleep_quality   study_method  \\\n",
       "0                   no          4.9       average  online videos   \n",
       "1                  yes          4.7          poor     self-study   \n",
       "2                  yes          5.8          poor       coaching   \n",
       "3                  yes          8.3       average    group study   \n",
       "4                  yes          9.6          good     self-study   \n",
       "...                ...          ...           ...            ...   \n",
       "629995             yes          4.1          good          mixed   \n",
       "629996             yes          4.5       average          mixed   \n",
       "629997             yes          4.3          poor  online videos   \n",
       "629998             yes          8.2       average    group study   \n",
       "629999             yes          5.8          poor  online videos   \n",
       "\n",
       "       facility_rating exam_difficulty  exam_score  \n",
       "0                  low            easy      78.300  \n",
       "1               medium        moderate      46.700  \n",
       "2                 high        moderate      99.000  \n",
       "3                 high        moderate      63.900  \n",
       "4                 high            easy     100.000  \n",
       "...                ...             ...         ...  \n",
       "629995            high        moderate      69.500  \n",
       "629996             low        moderate      78.900  \n",
       "629997             low        moderate      19.599  \n",
       "629998            high        moderate      59.100  \n",
       "629999             low            easy      37.200  \n",
       "\n",
       "[630000 rows x 13 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>course</th>\n",
       "      <th>study_hours</th>\n",
       "      <th>class_attendance</th>\n",
       "      <th>internet_access</th>\n",
       "      <th>sleep_hours</th>\n",
       "      <th>sleep_quality</th>\n",
       "      <th>study_method</th>\n",
       "      <th>facility_rating</th>\n",
       "      <th>exam_difficulty</th>\n",
       "      <th>exam_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>b.sc</td>\n",
       "      <td>7.91</td>\n",
       "      <td>98.8</td>\n",
       "      <td>no</td>\n",
       "      <td>4.9</td>\n",
       "      <td>average</td>\n",
       "      <td>online videos</td>\n",
       "      <td>low</td>\n",
       "      <td>easy</td>\n",
       "      <td>78.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>other</td>\n",
       "      <td>diploma</td>\n",
       "      <td>4.95</td>\n",
       "      <td>94.8</td>\n",
       "      <td>yes</td>\n",
       "      <td>4.7</td>\n",
       "      <td>poor</td>\n",
       "      <td>self-study</td>\n",
       "      <td>medium</td>\n",
       "      <td>moderate</td>\n",
       "      <td>46.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>female</td>\n",
       "      <td>b.sc</td>\n",
       "      <td>4.68</td>\n",
       "      <td>92.6</td>\n",
       "      <td>yes</td>\n",
       "      <td>5.8</td>\n",
       "      <td>poor</td>\n",
       "      <td>coaching</td>\n",
       "      <td>high</td>\n",
       "      <td>moderate</td>\n",
       "      <td>99.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "      <td>b.sc</td>\n",
       "      <td>2.00</td>\n",
       "      <td>49.5</td>\n",
       "      <td>yes</td>\n",
       "      <td>8.3</td>\n",
       "      <td>average</td>\n",
       "      <td>group study</td>\n",
       "      <td>high</td>\n",
       "      <td>moderate</td>\n",
       "      <td>63.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>male</td>\n",
       "      <td>bca</td>\n",
       "      <td>7.65</td>\n",
       "      <td>86.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>9.6</td>\n",
       "      <td>good</td>\n",
       "      <td>self-study</td>\n",
       "      <td>high</td>\n",
       "      <td>easy</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629995</th>\n",
       "      <td>629995</td>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>b.tech</td>\n",
       "      <td>4.86</td>\n",
       "      <td>70.7</td>\n",
       "      <td>yes</td>\n",
       "      <td>4.1</td>\n",
       "      <td>good</td>\n",
       "      <td>mixed</td>\n",
       "      <td>high</td>\n",
       "      <td>moderate</td>\n",
       "      <td>69.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629996</th>\n",
       "      <td>629996</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>ba</td>\n",
       "      <td>7.08</td>\n",
       "      <td>54.4</td>\n",
       "      <td>yes</td>\n",
       "      <td>4.5</td>\n",
       "      <td>average</td>\n",
       "      <td>mixed</td>\n",
       "      <td>low</td>\n",
       "      <td>moderate</td>\n",
       "      <td>78.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629997</th>\n",
       "      <td>629997</td>\n",
       "      <td>24</td>\n",
       "      <td>male</td>\n",
       "      <td>bca</td>\n",
       "      <td>0.64</td>\n",
       "      <td>44.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>4.3</td>\n",
       "      <td>poor</td>\n",
       "      <td>online videos</td>\n",
       "      <td>low</td>\n",
       "      <td>moderate</td>\n",
       "      <td>19.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629998</th>\n",
       "      <td>629998</td>\n",
       "      <td>20</td>\n",
       "      <td>male</td>\n",
       "      <td>b.com</td>\n",
       "      <td>1.54</td>\n",
       "      <td>75.1</td>\n",
       "      <td>yes</td>\n",
       "      <td>8.2</td>\n",
       "      <td>average</td>\n",
       "      <td>group study</td>\n",
       "      <td>high</td>\n",
       "      <td>moderate</td>\n",
       "      <td>59.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629999</th>\n",
       "      <td>629999</td>\n",
       "      <td>18</td>\n",
       "      <td>other</td>\n",
       "      <td>b.tech</td>\n",
       "      <td>3.94</td>\n",
       "      <td>75.3</td>\n",
       "      <td>yes</td>\n",
       "      <td>5.8</td>\n",
       "      <td>poor</td>\n",
       "      <td>online videos</td>\n",
       "      <td>low</td>\n",
       "      <td>easy</td>\n",
       "      <td>37.200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630000 rows × 13 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:37.345691Z",
     "start_time": "2026-01-22T08:41:37.240469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# find missing values\n",
    "missing_values = df_train.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "if not missing_values.empty:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=missing_values.index, y=missing_values.values, palette='viridis')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Missing Values')\n",
    "    plt.title('Missing Values per Feature')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"✅ No missing values found in the dataset.\")"
   ],
   "id": "a3fa8ca7462c6fcc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ No missing values found in the dataset.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:37.772592Z",
     "start_time": "2026-01-22T08:41:37.358146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# replace all inf/-inf with NaN\n",
    "df_test.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "df_test.fillna(0, inplace=True)\n",
    "\n",
    "df_train.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "df_train.fillna(0, inplace=True)"
   ],
   "id": "ebba76daac804af",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:37.786751Z",
     "start_time": "2026-01-22T08:41:37.783954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print all existing categories and their percentages.\n",
    "if verbose:\n",
    "    cols = [\"gender\", \"course\", \"internet_access\", \"sleep_quality\", \"study_method\", \"facility_rating\"]\n",
    "    for col in cols:\n",
    "        print(f\"\\nColumn: `{col}`\")\n",
    "        vc = df_train[col].value_counts(dropna=False, normalize=True) * 100\n",
    "        for name, pct in vc.items():\n",
    "            print(f\"  {name:13}: {pct:6.2f}%\")"
   ],
   "id": "c198e9bb6d5c1459",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:37.793601Z",
     "start_time": "2026-01-22T08:41:37.790817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# map categories, e.g. male->0, female->1\n",
    "def map_column_values(col, mapping, dataframes):\n",
    "    # Case-insensitive mapping that preserves missing values\n",
    "    map_lower = {k.lower(): v for k, v in mapping.items()}\n",
    "\n",
    "    def map_series_ci(series, mapping_lower):\n",
    "        mask_na = series.isna()\n",
    "        s = series.astype(str).str.strip().str.lower()\n",
    "        s = s.where(~mask_na, pd.NA)  # keep original missing as <NA>\n",
    "        return s.map(mapping_lower).astype(\"Int64\")\n",
    "\n",
    "    for df in dataframes:\n",
    "        df[col] = map_series_ci(df[col], map_lower)\n",
    "        values = df[col].value_counts(dropna=False)\n",
    "        if verbose:\n",
    "            print(values)"
   ],
   "id": "552f470c2fcb230f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:37.798337Z",
     "start_time": "2026-01-22T08:41:37.796785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# mapping = {\"Female\": 0, \"Other\": 1,\"Male\": 2}\n",
    "# map_column_values(\"gender\", mapping, [df_train, df_test])\n",
    "#\n",
    "# mapping = {\"No formal\": 0, \"Highschool\": 1, \"Graduate\": 2, \"Postgraduate\": 3}\n",
    "# map_column_values(\"education_level\", mapping, [df_train, df_test])\n",
    "#\n",
    "# mapping = {\"Low\": 0, \"Lower-Middle\": 1, \"Middle\": 2, \"Upper-Middle\": 3, \"High\": 4}\n",
    "# map_column_values(\"income_level\", mapping, [df_train, df_test])\n",
    "#\n",
    "# mapping = {\"Unemployed\": 0, \"Retired\": 1, \"Employed\": 2, \"Student\": 3}\n",
    "# map_column_values(\"employment_status\", mapping, [df_train, df_test])\n",
    "#\n",
    "# mapping = {\"Never\": 0, \"Former\": 1, \"Current\": 2}\n",
    "# map_column_values(\"smoking_status\", mapping, [df_train, df_test])"
   ],
   "id": "76354e9cb5ad4286",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:37.804877Z",
     "start_time": "2026-01-22T08:41:37.802611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_derived_features(dataframes):\n",
    "    for df in dataframes:\n",
    "        # tri_term = df[\"triglycerides\"] / 88.5 / np.where(gender_female, 0.81, 1.03)\n",
    "\n",
    "\n",
    "        #df[\"physical_inactivity\"] = 1.0 / (df[\"physical_activity_minutes_per_week\"] + 0.0000001)\n",
    "\n",
    "\n",
    "        #df.drop(columns=[\"age\"], inplace=True)\n",
    "\n",
    "\n",
    "        pass\n",
    "\n",
    "add_derived_features([df_train, df_test])\n",
    "one_hot_features = [\"course\", \"gender\",\"internet_access\", \"sleep_quality\", \"study_method\", \"facility_rating\", \"exam_difficulty\"]\n",
    "# one_hot_features = [\"ethnicity\", \"gender\", \"education_level\", \"income_level\", \"employment_status\", \"smoking_status\"]"
   ],
   "id": "37f1b8ed77cdfd69",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:37.809767Z",
     "start_time": "2026-01-22T08:41:37.808163Z"
    }
   },
   "cell_type": "code",
   "source": "# df_test",
   "id": "8a2369bd538d1812",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:38.143327Z",
     "start_time": "2026-01-22T08:41:37.812452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# one hot encoding\n",
    "def one_hot_encode(df, features):\n",
    "    df_out = df.copy()\n",
    "    dummies = pd.get_dummies(df_out[features], prefix=features, dummy_na=False)  # one hot encode\n",
    "    df_out = df_out.drop(columns=features)  # remove original features from df\n",
    "    df_out = pd.concat([df_out, dummies], axis=1)  # add one hot encoded columns to df\n",
    "    return df_out\n",
    "\n",
    "X_training = one_hot_encode(df_train, one_hot_features) # One hot encode training set\n",
    "X_test = one_hot_encode(df_test, one_hot_features) # One hot encode test set\n",
    "# X_training"
   ],
   "id": "2e4e9252479e689d",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:38.149778Z",
     "start_time": "2026-01-22T08:41:38.148334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# X_test\n",
    "# 57, 0, 400, 5.9, 6.8, 11, 22, 0.86, 132, 85, 62 (heart rate)"
   ],
   "id": "deebac78c042ff26",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:38.324293Z",
     "start_time": "2026-01-22T08:41:38.152833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# the target\n",
    "y_init = X_training[\"exam_score\"]\n",
    "\n",
    "\n",
    "# transform y into an array\n",
    "y_str = y_init.astype(str)\n",
    "le = LabelEncoder().fit(y_str)\n",
    "y = le.transform(y_str)\n",
    "# X_training"
   ],
   "id": "b4fb1663b3a1b368",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:38.337672Z",
     "start_time": "2026-01-22T08:41:38.333998Z"
    }
   },
   "cell_type": "code",
   "source": "y_init",
   "id": "b4e1c3028d1cd89b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          78.300\n",
       "1          46.700\n",
       "2          99.000\n",
       "3          63.900\n",
       "4         100.000\n",
       "           ...   \n",
       "629995     69.500\n",
       "629996     78.900\n",
       "629997     19.599\n",
       "629998     59.100\n",
       "629999     37.200\n",
       "Name: exam_score, Length: 630000, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:38.370920Z",
     "start_time": "2026-01-22T08:41:38.362246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# how many different classes does the target have?\n",
    "n_classes = len(np.unique(y))\n",
    "if verbose:\n",
    "    print(\"Target shape:\", getattr(y, \"shape\", None), \"unique classes:\", np.unique(y))\n",
    "    print(f\"{n_classes=}\")"
   ],
   "id": "633f340549e7803f",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:38.390540Z",
     "start_time": "2026-01-22T08:41:38.388291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_model_kwargs(n_classes, n_estimators=2000, learning_rate=0.03, max_depth=4, subsample=0.8, colsample_bytree=0.8, early_stopping_rounds=50):\n",
    "    if n_classes == 0:\n",
    "        raise RuntimeError(\"Target `y` is empty — check earlier processing (dropped column or filled with NaN).\")\n",
    "    if n_classes == 1:\n",
    "        raise RuntimeError(f\"Only one class present ({np.unique(y)[0]}). Cannot train a classifier.\")\n",
    "    if n_classes == 2:\n",
    "        model_kwargs = {\n",
    "            \"objective\": \"binary:logistic\",  # choose objective and eval_metric based on number of classes\n",
    "            \"eval_metric\": \"logloss\",\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"max_depth\": max_depth,\n",
    "            \"subsample\": subsample,\n",
    "            \"colsample_bytree\": colsample_bytree,\n",
    "            \"tree_method\": \"hist\",\n",
    "            \"early_stopping_rounds\": early_stopping_rounds,\n",
    "        }\n",
    "    elif n_classes > 2:\n",
    "        model_kwargs = {\n",
    "            \"objective\": \"multi:softprob\",\n",
    "            \"num_class\": n_classes,\n",
    "            \"eval_metric\": \"mlogloss\",\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"max_depth\": max_depth,\n",
    "            \"subsample\": subsample,\n",
    "            \"colsample_bytree\": colsample_bytree,\n",
    "            \"tree_method\": \"hist\",\n",
    "            \"early_stopping_rounds\": early_stopping_rounds,\n",
    "        }\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "    return model_kwargs"
   ],
   "id": "5ef76f5d23016be6",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:38.456089Z",
     "start_time": "2026-01-22T08:41:38.449669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # COMPARING MODELS PATH\n",
    "def validate_model(n_estimators, learning_rate, max_depth, subsample, colsample_bytree, early_stopping_rounds, model=\"xgb\"):\n",
    "    # kwargs = generate_model_kwargs(n_classes, n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth,\n",
    "    #                                      subsample=subsample, colsample_bytree=colsample_bytree, early_stopping_rounds=early_stopping_rounds)\n",
    "    n_splits = 5\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    if n_classes == 2:\n",
    "        oof_preds = np.zeros(len(y), dtype=float)\n",
    "    else:\n",
    "        oof_preds = np.zeros((len(y), n_classes), dtype=float)\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(X_training, y), start=1):\n",
    "        X_tr, X_val = X_training.iloc[tr_idx], X_training.iloc[val_idx]\n",
    "        y_tr, y_val = y[tr_idx], y[val_idx]\n",
    "\n",
    "        if model == \"xgb\":  # XGBoost\n",
    "            if n_classes == 2:\n",
    "                kwargs = {\n",
    "                    \"objective\": \"binary:logistic\",  # choose objective and eval_metric based on number of classes\n",
    "                    \"eval_metric\": \"logloss\",\n",
    "                    \"n_estimators\": n_estimators,\n",
    "                    \"learning_rate\": learning_rate,\n",
    "                    \"max_depth\": max_depth,\n",
    "                    \"subsample\": subsample,\n",
    "                    \"colsample_bytree\": colsample_bytree,\n",
    "                    \"tree_method\": \"hist\",\n",
    "                    \"early_stopping_rounds\": early_stopping_rounds,\n",
    "                }\n",
    "            elif n_classes > 2:\n",
    "                kwargs = {\n",
    "                    \"objective\": \"multi:softprob\",\n",
    "                    \"num_class\": n_classes,\n",
    "                    \"eval_metric\": \"mlogloss\",\n",
    "                    \"n_estimators\": n_estimators,\n",
    "                    \"learning_rate\": learning_rate,\n",
    "                    \"max_depth\": max_depth,\n",
    "                    \"subsample\": subsample,\n",
    "                    \"colsample_bytree\": colsample_bytree,\n",
    "                    \"tree_method\": \"hist\",\n",
    "                    \"early_stopping_rounds\": early_stopping_rounds,\n",
    "                }\n",
    "            else:\n",
    "                raise ValueError(f\"Function validate_model(): Target has no or only 1 class. {n_classes=}\")\n",
    "            m = XGBClassifier(**kwargs, random_state=42 + fold)\n",
    "            m.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=0)\n",
    "        elif model == \"lgbm\":  # LightGBM\n",
    "            kwargs = {\n",
    "                \"n_estimators\": n_estimators,\n",
    "                \"learning_rate\": learning_rate,\n",
    "                \"max_depth\": max_depth,\n",
    "                \"subsample\": subsample,\n",
    "                \"colsample_bytree\": colsample_bytree,\n",
    "                \"random_state\": 42 + fold,\n",
    "                \"n_jobs\": -1,\n",
    "            }\n",
    "            m = lightgbm.LGBMClassifier(**kwargs)\n",
    "            m.fit(X_tr, y_tr, eval_set=[(X_val, y_val)])\n",
    "        elif model == \"catboost\":\n",
    "            kwargs = {\n",
    "                \"iterations\": n_estimators,\n",
    "                \"learning_rate\": learning_rate,\n",
    "                \"depth\": max_depth,\n",
    "                \"random_state\": 42 + fold,\n",
    "                \"verbose\": False,\n",
    "            }\n",
    "            m = CatBoostClassifier(**kwargs)\n",
    "            m.fit(X_tr, y_tr, eval_set=(X_val, y_val), early_stopping_rounds=early_stopping_rounds, verbose=False)\n",
    "        elif model == \"randomforest\":  # very slow, usually bad model\n",
    "            kwargs = {\n",
    "                \"n_estimators\": n_estimators,\n",
    "                \"max_depth\": max_depth,\n",
    "                \"max_features\": colsample_bytree,  # sklearn accepts float for max_features as fraction of features\n",
    "                \"random_state\": 42 + fold,\n",
    "                \"n_jobs\": -1,\n",
    "            }\n",
    "            m = RandomForestClassifier(**kwargs)\n",
    "            m.fit(X_tr, y_tr)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown model. Choose from xgb, lgbm, catboost, randomforest.\")\n",
    "\n",
    "        if n_classes == 2:\n",
    "            oof_preds[val_idx] = m.predict_proba(X_val)[:, 1]\n",
    "        else:\n",
    "            oof_preds[val_idx] = m.predict_proba(X_val)\n",
    "    # set items of oof_preds to 0.499\n",
    "    # low_thr, high_thr = 0.5, 0.55\n",
    "    # if n_classes == 2:\n",
    "    #     mask = (oof_preds > low_thr) & (oof_preds < high_thr)\n",
    "    #     oof_preds[mask] = 0.499\n",
    "    # else:\n",
    "    #     mask = (oof_preds > low_thr) & (oof_preds < high_thr)\n",
    "    #     oof_preds[mask] = 0.499\n",
    "    #     renormalize rows to sum to 1 to keep valid probability distributions\n",
    "        # row_sums = oof_preds.sum(axis=1, keepdims=True)\n",
    "        # row_sums[row_sums == 0] = 1.0\n",
    "        # oof_preds = oof_preds / row_sums\n",
    "    if n_classes == 2:\n",
    "        auc = roc_auc_score(y, oof_preds)\n",
    "        logloss = log_loss(y, oof_preds)\n",
    "        brier = brier_score_loss(y, oof_preds)\n",
    "    else:\n",
    "        auc = roc_auc_score(y, oof_preds, multi_class=\"ovr\")\n",
    "        logloss = log_loss(y, oof_preds)\n",
    "        brier = np.mean([brier_score_loss((y == c).astype(int), oof_preds[:, c]) for c in range(n_classes)])\n",
    "    return auc, logloss, brier"
   ],
   "id": "a2b5e78166a6a6e8",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### OOF predictions\n",
    "Probability predictions for each training sample produced by models that did not train on that sample (via cross‑validation).\n",
    "They give an approximately unbiased estimate of how the model will behave on new data.\n",
    "### Metrics (what they measure, range, interpretation)\n",
    "#### AUC / ROC AUC\n",
    "What: area under the Receiver Operating Characteristic curve (TPR vs FPR).\n",
    "Range: 0.0–1.0 (0.5 = random). Higher is better.\n",
    "Interpretation: measures ranking/separability of positive vs negative; insensitive to predicted‑probability calibration.\n",
    "#### Log loss (cross‑entropy)\n",
    "What: average negative log likelihood of the true labels given predicted probabilities.\n",
    "Range: [0, ∞) (lower is better; 0 is perfect).\n",
    "Interpretation: penalizes overconfident wrong predictions strongly; sensitive to calibration and probability confidence.\n",
    "#### Brier score\n",
    "What: mean squared error between predicted probability and actual outcome (0/1).\n",
    "Range: [0, 1] for binary targets (lower is better).\n",
    "Interpretation: measures both calibration and refinement; decomposable into calibration + discrimination components.\n",
    "\n",
    "### Models\n",
    "#### LGBM\n",
    "[Documentation](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html)\n",
    "[Introductory blogpost](https://www.kdnuggets.com/2023/07/lgbmclassifier-gettingstarted-guide.html)"
   ],
   "id": "f8d7fc520a6ebee1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:38.477301Z",
     "start_time": "2026-01-22T08:41:38.474250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# COMPARING MODELS PATH\n",
    "# Next:\n",
    "#   Die von Kaggle in der Competition benutzte Metric mit aufnehmen\n",
    "if validate_models:\n",
    "    # ne_list = [6000]\n",
    "    ne_list = [2000]\n",
    "    # lr_list = [0.02]\n",
    "    lr_list = [0.07]\n",
    "    # md_list = [6]\n",
    "    md_list = [4]\n",
    "    ss_list = [0.8]\n",
    "    cb_list = [0.2]\n",
    "    models = [\"lgbm\"]\n",
    "    # models = [\"xgb\", \"lgbm\", \"catboost\", \"randomforest\"]\n",
    "    print(f\"Comparing {len(ne_list)*len(lr_list)*len(md_list)*len(ss_list)*len(cb_list)*len(models)} different models \")\n",
    "    counter = 0\n",
    "    tic = time.perf_counter()\n",
    "    for ne in ne_list:\n",
    "        for lr in lr_list:\n",
    "            for md in md_list:\n",
    "                for ss in ss_list:\n",
    "                    for cb in cb_list:\n",
    "                        for model in models:\n",
    "                            auc, logloss, brier = validate_model(n_estimators=ne, learning_rate=lr, max_depth=md, subsample=ss, colsample_bytree=cb, early_stopping_rounds=50, model=model)\n",
    "                            new_tic = time.perf_counter()\n",
    "                            minutes = (new_tic - tic) / 60\n",
    "                            tic = new_tic\n",
    "                            counter += 1\n",
    "                            line = f\"{counter};{ne:3};{lr:.3f};{md};{ss:.2f};{cb:.2f};{auc:.6f};{logloss:.6f};{brier:.6f};{model};{minutes:.2f}\"\n",
    "                            print(line)\n",
    "                            if sound:\n",
    "                                winsound.Beep(frequency=500, duration=300)\n",
    "                            # header = \"count;ne;lr;md;ss;cb;tm;auc;logloss;brier;model;minutes\"\n",
    "                            with open(\"model_comparisons.csv\", \"a\", encoding=\"utf8\") as f:\n",
    "                                f.write(line + \"\\n\")\n",
    "    if sound:\n",
    "        winsound.Beep(frequency=1000, duration=1000)\n"
   ],
   "id": "29d0c928272abac3",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Submission Path\n",
    "The following code is only to be executed when generating a file for submission."
   ],
   "id": "21950cee0cf29e9f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:38.485248Z",
     "start_time": "2026-01-22T08:41:38.483569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SUBMISSION PATH\n",
    "if submit_prediction:\n",
    "    # choose seeds. There will be trained a model for each seed\n",
    "    # seeds = [42]\n",
    "    # seeds = [42, 33, 77, 99, 101]\n",
    "    seeds = [i for i in range(1)]   # change this to run a number of different models"
   ],
   "id": "ac6d976fbc49a5fa",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:41:38.493214Z",
     "start_time": "2026-01-22T08:41:38.490943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SUBMISSION PATH\n",
    "# train models and keep them in a list\n",
    "if submit_prediction and MODEL == \"xgb\":\n",
    "    models = []\n",
    "    if n_classes == 2:\n",
    "        kwargs = {\n",
    "            \"objective\": \"binary:logistic\",  # choose objective and eval_metric based on number of classes\n",
    "            \"eval_metric\": \"logloss\",\n",
    "            \"n_estimators\": 1,\n",
    "            \"learning_rate\": 1,\n",
    "            \"subsample\": 0.8,\n",
    "            \"colsample_bytree\": 0.2,\n",
    "            \"tree_method\": \"hist\",\n",
    "            \"early_stopping_rounds\": 50,\n",
    "        }\n",
    "    # elif n_classes > 2:\n",
    "    #     kwargs = {\n",
    "    #         \"objective\": \"multi:softprob\",\n",
    "    #         \"num_class\": n_classes,\n",
    "    #         \"eval_metric\": \"mlogloss\",\n",
    "    #         \"n_estimators\": n_estimators,\n",
    "    #         \"learning_rate\": learning_rate,\n",
    "    #         \"max_depth\": max_depth,\n",
    "    #         \"subsample\": subsample,\n",
    "    #         \"colsample_bytree\": colsample_bytree,\n",
    "    #         \"tree_method\": \"hist\",\n",
    "    #         \"early_stopping_rounds\": early_stopping_rounds,\n",
    "    #     }\n",
    "    else:\n",
    "        raise ValueError(f\"Function validate_model(): Target has no or only 1 class. {n_classes=}\")\n",
    "    for s in seeds:\n",
    "        # take 80% of the trainingsdata, then split these 80% again to obtain trainings and validation data\n",
    "        X_train, _, y_train, _ = train_test_split(X_training, y, test_size=0.2, random_state=s, stratify=y)\n",
    "        X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=s, stratify=y_train)\n",
    "\n",
    "        model = XGBClassifier(**kwargs, early_stopping_rounds=50, random_state=s)\n",
    "        model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=0)\n",
    "        models.append(model)"
   ],
   "id": "5a4376f52160aaf9",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:42:03.070573Z",
     "start_time": "2026-01-22T08:41:38.496264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SUBMISSION PATH\n",
    "# train models and keep them in a list\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if submit_prediction and MODEL == \"lgbm\":\n",
    "    models = []\n",
    "    kwargs = {\n",
    "        \"n_estimators\": 5000,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"max_depth\": -1,          # often better than forcing 6\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.8,  # 0.2 can be too restrictive\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"objective\": \"regression\",\n",
    "    }\n",
    "\n",
    "    for s in seeds:\n",
    "        X_train, _, y_train, _ = train_test_split(\n",
    "            X_training, y, test_size=0.2, random_state=s\n",
    "        )\n",
    "        X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "            X_train, y_train, test_size=0.2, random_state=s\n",
    "        )\n",
    "\n",
    "        suppress_python_output()\n",
    "        model = lgb.LGBMRegressor(**kwargs)\n",
    "\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric=\"rmse\",\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]\n",
    "        )\n",
    "        restore_python_output()\n",
    "\n",
    "        models.append(model)"
   ],
   "id": "7e8c70e986f90b21",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:42:03.612792Z",
     "start_time": "2026-01-22T08:42:03.168791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SUBMISSION PATH\n",
    "# Make sure column order in test data matches training data:\n",
    "if submit_prediction:\n",
    "    X_test_final = X_test[X_training.columns]\n",
    "X_test_final"
   ],
   "id": "bf622f9fdca103d4",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['exam_score'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# SUBMISSION PATH\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Make sure column order in test data matches training data:\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m submit_prediction:\n\u001B[0;32m----> 4\u001B[0m     X_test_final \u001B[38;5;241m=\u001B[39m \u001B[43mX_test\u001B[49m\u001B[43m[\u001B[49m\u001B[43mX_training\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m      5\u001B[0m X_test_final\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4106\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[1;32m   4107\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[0;32m-> 4108\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcolumns\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m   4110\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[1;32m   4111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[0;34m(self, key, axis_name)\u001B[0m\n\u001B[1;32m   6197\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   6198\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[0;32m-> 6200\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   6202\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[1;32m   6203\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[1;32m   6204\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:6252\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[0;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[1;32m   6249\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   6251\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[0;32m-> 6252\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"['exam_score'] not in index\""
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T08:42:03.616061Z",
     "start_time": "2026-01-20T07:48:35.440882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SUBMISSION PATH\n",
    "# predict on final test set and average probs\n",
    "if submit_prediction:\n",
    "    probs = []\n",
    "    for model in models:\n",
    "        bi = getattr(model, \"best_iteration\", None)\n",
    "        if bi is not None:\n",
    "            probs.append(model.predict_proba(X_test_final, iteration_range=(0, bi + 1))[:, 1])\n",
    "        else:\n",
    "            probs.append(model.predict_proba(X_test_final)[:, 1])\n",
    "        # probs shape: seeds x samples x classes  , classes is = 1 here due to indexing\n",
    "\n",
    "    probs_arr = np.vstack(probs)   # shape: (n_models, n_samples)\n",
    "    mean_prob = probs_arr.mean(axis=0)\n",
    "\n",
    "    # set items of mean_prob to 0.0 if they are < 0.2 and to 1.0 if they are > 0.8\n",
    "    # mean_prob = np.asarray(mean_prob, dtype=float)  # ensure numpy array\n",
    "    # low_thr = 0.5\n",
    "    # high_thr = 0.5\n",
    "    # mean_prob[mean_prob < low_thr] = 0.0\n",
    "    # mean_prob[mean_prob > high_thr] = 1.0\n",
    "# mean_prob"
   ],
   "id": "faac049af5fa9e70",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 13\u001B[0m\n\u001B[1;32m     10\u001B[0m             probs\u001B[38;5;241m.\u001B[39mappend(model\u001B[38;5;241m.\u001B[39mpredict_proba(X_test_final)[:, \u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m     11\u001B[0m         \u001B[38;5;66;03m# probs shape: seeds x samples x classes  , classes is = 1 here due to indexing\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m     probs_arr \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprobs\u001B[49m\u001B[43m)\u001B[49m   \u001B[38;5;66;03m# shape: (n_models, n_samples)\u001B[39;00m\n\u001B[1;32m     14\u001B[0m     mean_prob \u001B[38;5;241m=\u001B[39m probs_arr\u001B[38;5;241m.\u001B[39mmean(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;66;03m# set items of mean_prob to 0.0 if they are < 0.2 and to 1.0 if they are > 0.8\u001B[39;00m\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;66;03m# mean_prob = np.asarray(mean_prob, dtype=float)  # ensure numpy array\u001B[39;00m\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;66;03m# low_thr = 0.5\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;66;03m# mean_prob[mean_prob > high_thr] = 1.0\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# mean_prob\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/_core/shape_base.py:292\u001B[0m, in \u001B[0;36mvstack\u001B[0;34m(tup, dtype, casting)\u001B[0m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arrs, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    291\u001B[0m     arrs \u001B[38;5;241m=\u001B[39m (arrs,)\n\u001B[0;32m--> 292\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_nx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcasting\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcasting\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValueError\u001B[0m: need at least one array to concatenate"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# SUBMISSION PATH (REGRESSION)\n",
    "if submit_prediction:\n",
    "    preds = []\n",
    "    for model in models:\n",
    "        bi = getattr(model, \"best_iteration_\", None)  # note the trailing underscore in sklearn API\n",
    "        if bi is not None:\n",
    "            preds.append(model.predict(X_test_final, num_iteration=bi))\n",
    "        else:\n",
    "            preds.append(model.predict(X_test_final))\n",
    "\n",
    "    preds_arr = np.vstack(preds)      # (n_models, n_samples)\n",
    "    mean_pred = preds_arr.mean(axis=0)\n",
    "\n",
    "# mean_pred is your final prediction vector"
   ],
   "id": "15c2ab6ecc673a04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "2) 0.70160\n",
    "OneHot: [\"ethnicity\", \"employment_status\"]\n",
    "Mapping: [\"gender\", \"education_level\", \"income_level\", \"smoking_status\"]\n",
    "Fitting: 80% from 80%, 10 fits, \"n_estimators\": 2000\n",
    "3) 0.70159\n",
    "Fitting: 80% from 80%, 10 fits, \"n_estimators\": 2000\n",
    "4) 0.70163\n",
    "Fitting: 80% from 80%, 10 fits, \"n_estimators\": 3000\n",
    "5) debugging\n",
    "6) 0.70101\n",
    "Fitting: 80% from 80%, 2 fits, \"n_estimators\": 5000\n",
    "7) 0.70166\n",
    "Fitting: 80% from 80%, 15 fits, \"n_estimators\" etc. 5000, 0.03, 4, 0.8, 0.8\n",
    "8) 0.70191\n",
    "Fitting: 80% from 80%, 15 fits, \"n_estimators\" etc. 8000, 0.01, 5, 0.9, 0.5\n",
    "9) 0.70301\n",
    "Fitting: LGBM!!! 80% from 80%, 15 fits, \"n_estimators\" etc. 2000, 0.07, 4, 0.8, 0.8\n",
    "10) 0.70084\n",
    "Fitting: LGBM!!! 80% from 80%, 15 fits, \"n_estimators\" etc. 2000, 0.07, 4, 0.8, 0.8\n",
    "<0.2 -> 0.0, >0.8 -> 1.0\n",
    "11) 0.70300\n",
    "Fitting: LGBM!!! 80% from 80%, 15 fits, \"n_estimators\" etc. 2000, 0.07, 4, 0.8, 0.8\n",
    "<0.05 -> 0.0, >0.95 -> 1.0\n",
    "12) 0.61863\n",
    "Fitting: LGBM!!! 80% from 80%, 15 fits, \"n_estimators\" etc. 2000, 0.07, 4, 0.8, 0.8\n",
    "<0.5 -> 0.0, >0.5 -> 1.0\n",
    "13) 0.70324\n",
    "Fitting: LGBM!!! 80% from 80%, 15 fits, \"n_estimators\" etc. 4000, 0.03, 4, 0.9, 0.5\n",
    "14) 0.70364\n",
    "Fitting: LGBM, 80% from 80%, 15 fits, \"n_estimators\" etc. 6000, 0.02, 6, 0.8, 0.2\n",
    "15) 0.70222\n",
    "NO ORIGINAL DATA!!!!, Fitting: LGBM, 80% from 80%, 15 fits, \"n_estimators\" etc. 6000, 0.02, 6, 0.8, 0.2\n",
    "16) 0.70281\n",
    "+6 derived features TG_HDL_Ratio LDL_HDL_Ratio MAP Pulse_Pressure Central_Obesity_Index Sleep_Deviation\n",
    "Fitting: LGBM, 80% from 80%, 15 fits, \"n_estimators\" etc. 6000, 0.02, 6, 0.8, 0.2\n",
    "17) 0.70322\n",
    "+1 physical_inactivity\n",
    "Fitting: LGBM, 80% from 80%, 15 fits, \"n_estimators\" etc. 40000, 0.005, 6, 0.8, 0.2\n",
    "18) 0.70381\n",
    "+1 physical_inactivity\n",
    "Fitting: LGBM, 80% from 80%, 15 fits, \"n_estimators\" etc. 6000, 0.02, 6, 0.8, 0.2\n",
    "19) 0.70341\n",
    "+1 physical_inactivity -1 physical_activity_minutes_per_week\n",
    "Fitting: LGBM, 80% from 80%, 15 fits, \"n_estimators\" etc. 6000, 0.02, 6, 0.8, 0.2\n",
    "20) 0.70376\n",
    "+1 physical_inactivity, Replaced age with age_squared, +1 triglycerides_root\n",
    "Fitting: LGBM, 80% from 80%, 15 fits, \"n_estimators\" etc. 6000, 0.02, 6, 0.8, 0.2\n",
    "21) 0.70384\n",
    "+1 physical_inactivity, Replaced age with age_squared\n",
    "Fitting: LGBM, 80% from 80%, 15 fits, \"n_estimators\" etc. 6000, 0.02, 6, 0.8, 0.2\n",
    "\"\"\"\n",
    "pass"
   ],
   "id": "14b6f33b725a84b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Learnings\n",
    "#### Model\n",
    "- Random Forest is slow and bad.\n",
    "- LGBM ist faster and better than XGBoost.\n",
    "- Parameter \"subsample\" apparently has no effect on LGBM.\n",
    "- The higher n_estimators, the lower is the optimal learning rate.\n",
    "- 40000 perform better than 6000 in training data but worse with test data.\n",
    "#### Feature Enhancement\n",
    "- Setting the ID of all trainings data to zero worsens the outcome.\n",
    "- Ordinal Mapping instead of One HoT Encoding: no effect on XGB, bad effect on LGBM.\n",
    "- Tried 12 derived features. All worsened the outcome. Replacing base features with the features derived from them also worsened the outcome.\n",
    "- Removing any base feature worsens the score. The by far most important features are physical activity, diabetes family history, age, tryglycerides.\n",
    "#### Data\n",
    "- Including the original data for training worsens the validation outcome but improves the kaggle result on test data.\n",
    "- Including the original several times (as duplicates) has no effect."
   ],
   "id": "a7f77499520e8bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f44674cedd55ab73",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12184666,
     "sourceId": 91717,
     "sourceType": "competition"
    },
    {
     "datasetId": 8224289,
     "sourceId": 12993221,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2777.545807,
   "end_time": "2025-09-22T10:44:15.653257",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-22T09:57:58.107450",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
